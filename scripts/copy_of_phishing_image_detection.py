# -*- coding: utf-8 -*-
"""Copy of Phishing Image Detection

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/17x_l0nzVqbLiLGwT9r0rypyNgGgMMR40
"""

# 1. IMPORT LIBRARY YANG DIBUTUHKAN
# =================================================================
import tensorflow as tf
from tensorflow import keras
from tensorflow.keras import layers
import matplotlib.pyplot as plt
import numpy as np
import os

"""### 8. Simpan Model

Untuk tujuan deployment, kita perlu menyimpan model yang sudah terlatih. Format TensorFlow SavedModel adalah format yang direkomendasikan karena dapat dengan mudah dimuat dan digunakan di berbagai platform.

"""

import os

# Tentukan direktori tempat model akan disimpan
model_save_path = 'my_phishing_model'

# Simpan model
tf.saved_model.save(model, model_save_path)

print(f"Model berhasil disimpan di: {os.path.abspath(model_save_path)}")

"""Setelah model disimpan, langkah selanjutnya adalah membuat aplikasi web yang dapat memuat model ini dan menerima gambar dari pengguna. Anda bisa menggunakan framework seperti Flask atau FastAPI untuk membangun API sederhana yang:

1.  Menerima file gambar yang diunggah.
2.  Memuat model yang telah disimpan.
3.  Melakukan preprocessing pada gambar sesuai dengan input model Anda (misalnya, mengubah ukuran, normalisasi).
4.  Membuat prediksi menggunakan model.
5.  Mengembalikan hasil prediksi kepada pengguna.

Saya bisa memberikan contoh kode dasar untuk aplikasi web menggunakan Flask jika Anda ingin melanjutkan ke langkah tersebut.
"""

# 2. PERSIAPAN DATA (LOAD & PREPROCESS)
# =================================================================
dataset_dir = '/content/phishing-dataset'

batch_size = 32
img_height = 180
img_width = 180

train_ds = tf.keras.utils.image_dataset_from_directory(
  dataset_dir,
  validation_split=0.2,
  subset="training",
  seed=123,
  image_size=(img_height, img_width),
  batch_size=batch_size)

val_ds = tf.keras.utils.image_dataset_from_directory(
  dataset_dir,
  validation_split=0.2,
  subset="validation",
  seed=123,
  image_size=(img_height, img_width),
  batch_size=batch_size)

class_names = train_ds.class_names
print("Kelas yang terdeteksi:", class_names)

plt.figure(figsize=(10, 10))
for images, labels in train_ds.take(1):
  for i in range(9):
    ax = plt.subplot(3, 3, i + 1)
    plt.imshow(images[i].numpy().astype("uint8"))
    label_name = "Phishing" if class_names[labels[i]] == "phishing_site_1" else "Genuine"
    plt.title(label_name)
    plt.axis("off")
plt.show()

AUTOTUNE = tf.data.AUTOTUNE
train_ds = train_ds.cache().shuffle(1000).prefetch(buffer_size=AUTOTUNE)
val_ds = val_ds.cache().prefetch(buffer_size=AUTOTUNE)

# 3. MEMBUAT MODEL (ARSITEKTUR CNN SEDERHANA)
# =================================================================
num_classes = len(class_names)

model = keras.Sequential([
  layers.Rescaling(1./255, input_shape=(img_height, img_width, 3)),

  layers.Conv2D(16, 3, padding='same', activation='relu'),
  layers.MaxPooling2D(),

  layers.Conv2D(32, 3, padding='same', activation='relu'),
  layers.MaxPooling2D(),

  layers.Conv2D(64, 3, padding='same', activation='relu'),
  layers.MaxPooling2D(),

  layers.Dropout(0.2),

  layers.Flatten(),

  layers.Dense(128, activation='relu'),

  layers.Dense(1)
])

# 4. COMPILE MODEL (SIAPKAN MODEL UNTUK TRAINING)
# =================================================================
model.compile(optimizer='adam',
              loss=tf.keras.losses.BinaryCrossentropy(from_logits=True),
              metrics=['accuracy'])

model.summary()

# 5. TRAINING MODEL
# =================================================================
from sklearn.utils.class_weight import compute_class_weight
import numpy as np

labels = []
for _, l in train_ds.unbatch():
    labels.append(l.numpy())
labels = np.array(labels)

class_weights = compute_class_weight('balanced', classes=np.unique(labels), y=labels)
class_weight_dict = dict(enumerate(class_weights))

print(f"Bobot Kelas yang akan digunakan: {class_weight_dict}")
print("----------------------------------------------------")

epochs = 10
history = model.fit(
  train_ds,
  validation_data=val_ds,
  epochs=epochs,
  class_weight=class_weight_dict
)

# 6. EVALUASI MODEL (LIHAT HASIL TRAINING)
# =================================================================
acc = history.history['accuracy']
val_acc = history.history['val_accuracy']
loss = history.history['loss']
val_loss = history.history['val_loss']

epochs_range = range(epochs)

plt.figure(figsize=(12, 4))
plt.subplot(1, 2, 1)
plt.plot(epochs_range, acc, label='Training Accuracy')
plt.plot(epochs_range, val_acc, label='Validation Accuracy')
plt.legend(loc='lower right')
plt.title('Training and Validation Accuracy')

plt.subplot(1, 2, 2)
plt.plot(epochs_range, loss, label='Training Loss')
plt.plot(epochs_range, val_loss, label='Validation Loss')
plt.legend(loc='upper right')
plt.title('Training and Validation Loss')
plt.show()

# 7. COBA PREDIKSI GAMBAR BARU (SIMULASI DEPLOYMENT)
# =================================================================

image_path_to_predict = '/content/test/123people.com_141.png'

if os.path.exists(image_path_to_predict):
    img = tf.keras.utils.load_img(
        image_path_to_predict, target_size=(img_height, img_width)
    )
    img_array = tf.keras.utils.img_to_array(img)
    img_array = tf.expand_dims(img_array, 0)

    predictions = model.predict(img_array)
    score_tensor = tf.nn.sigmoid(predictions[0])

    score_value = score_tensor.numpy()[0]

    print(
        "Gambar ini {:.2f} persen kemungkinan PHISHING dan {:.2f} persen kemungkinan GENUINE."
        .format(100 * score_value, 100 * (1 - score_value))
    )
else:
    print(f"File tidak ditemukan di: {image_path_to_predict}")
    print("Silakan ganti 'image_path_to_predict' dengan path file gambar yang valid untuk mencoba prediksi.")